# CNN Hyperparameter Study

This project explores how various **design choices and hyperparameters** affect the performance of **Convolutional Neural Networks (CNNs)** on small image classification tasks using:

- A 10-class subset of **CIFAR-100**
- The **Imagenette** dataset

## ğŸ“Œ Objectives

We systematically investigate:

- Network **depth** and **width**
- Different **activation functions**: ReLU, LeakyReLU, Tanh, Sigmoid
- A variety of **optimizers** and **learning rates**
- The effect of **batch size** and **training duration**
- Trade-offs between learning speed, test accuracy, and overfitting

## ğŸ§ª Experiments

All experiments are based on a simple three-block CNN architecture, progressively modified to measure the impact of each factor.

### ğŸ› ï¸ Tools & Libraries Used

- **Python**
- **TensorFlow** and **Keras** â€“ for building and training CNN models
- **NumPy** â€“ for numerical operations
- **Pandas** â€“ for data handling
- **Matplotlib** & **Seaborn** â€“ for plotting and visualization
- **Scikit-learn** â€“ for preprocessing and evaluation
- **OpenCV** â€“ for image processing

## ğŸ“Š Results

The final report compares:

- Test accuracy
- Training curves
- Overfitting behavior
- Performance impact of architectural changes

## ğŸ“ Files

- `cnn-hyperparameter-study.ipynb`: Jupyter Notebook with all experiments and analysis.

## ğŸ“š Dataset Links

- **CIFAR-100 Subset**: A classic image classification dataset of 100 fine-grained classes. This project uses 10 randomly selected classes.  
  ğŸ”— [Download from Keras](https://www.cs.toronto.edu/~kriz/cifar.html)

- **Imagenette**: A smaller, easier subset of ImageNet used for quick experimentation and benchmarking.  
  ğŸ”— [Download from fast.ai](https://github.com/fastai/imagenette)


## ğŸ‘©â€ğŸ’» Author

**Ayesha Sultana**  
ğŸ“§ [mst.ayesha1702@gmail.com] 
- Course: *Introduction to Deep Learning* - 2025
- University of Turku, Finland
 


